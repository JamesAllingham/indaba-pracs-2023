{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is ongoing notebook\n",
    "Few things needs to be improved: \n",
    "- Create the graph using pure jax numpy and remove the few pytorch related things (torch.nn.Embedding to flax.nn.Embed)\n",
    "- Making the graph Bidirectional instead Unidirectional (Optional)\n",
    "- Training batchwise, instead of full pass\n",
    "- Checking a bit more GraphMapFeatures, GraphNetwork classes from jraph and how they do the message passing\n",
    "- Look more into the objective formulation. I.e. shall we do link prediction in unsupervised way, or since we have the rating use the rating as edge labels.\n",
    "- And finally make this notebook as Indaba_Prac Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import jax\n",
    "import jraph\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Sequence\n",
    "from flax import linen as nn\n",
    "import jax.numpy as jnp\n",
    "from data_prep import UniGraphDataPreparation\n",
    "from data_prep import subset_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147880044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147868828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147878820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      296     5.0  1147880044\n",
       "1       1      306     3.5  1147868817\n",
       "2       1      307     5.0  1147868828\n",
       "3       1      665     5.0  1147878820\n",
       "4       1      899     3.5  1147868510"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "ratings_df = pd.read_csv('../ml-25m/ratings.csv')\n",
    "movies_df = pd.read_csv('../ml-25m/movies.csv')\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4027019, 5), (1000, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_subset_df, movies_subset_df = subset_dataset(ratings_df=ratings_df, movies_df=movies_df)\n",
    "ratings_subset_df.shape, movies_subset_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings_subset_df.userId.unique()), len(ratings_subset_df.movieId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ratings_df\n",
    "del movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = UniGraphDataPreparation(ratings_df = ratings_subset_df, movies_df = movies_subset_df)\n",
    "train_graph, test_graph = graph.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11000, 19), (11000, 19))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph.nodes.shape, test_graph.nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4612067 , -0.2764672 , -1.2072662 , ...,  0.9139635 ,\n",
       "        -1.2479409 , -1.8211188 ],\n",
       "       [ 1.1204472 , -1.35316   ,  0.84818536, ...,  0.6455621 ,\n",
       "         0.6479968 , -0.6489184 ],\n",
       "       [-0.7850939 ,  1.2695131 , -0.65635425, ..., -0.09871044,\n",
       "        -0.76065737,  1.56671   ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node features\n",
    "train_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4066, 6204, 4034, ..., 2560, 9460, 4233])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check source nodes, in our case this corresponds to users\n",
    "train_graph.senders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4066, 6204, 4034, ..., 2560, 9460, 4233])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check destination nodes, in our case this corresponds to movies\n",
    "train_graph.senders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adopted from https://github.com/deepmind/jraph/blob/master/jraph/ogb_examples/train_flax.py\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  \"\"\"A flax MLP.\"\"\"\n",
    "  features: Sequence[int]\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, inputs):\n",
    "    x = inputs\n",
    "    for i, lyr in enumerate([nn.Dense(feat) for feat in self.features]):\n",
    "      x = lyr(x)\n",
    "      # if i != len(self.features) - 1:\n",
    "      x = nn.relu(x)\n",
    "    return x\n",
    "\n",
    "class EdgePredictor(nn.Module):\n",
    "  features: Sequence[int]\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, edge_features):\n",
    "    x = edge_features\n",
    "    for i, feat in enumerate(self.features):\n",
    "      x = nn.Dense(feat)(x)\n",
    "      if i != len(self.features) - 1:\n",
    "        x = nn.relu(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_embed_fn(latent_size):\n",
    "  def embed(inputs):\n",
    "    return nn.Dense(latent_size)(inputs)\n",
    "  return embed\n",
    "\n",
    "\n",
    "def make_mlp(features):\n",
    "  @jraph.concatenated_args\n",
    "  def update_fn(inputs):\n",
    "    return MLP(features)(inputs)\n",
    "  return update_fn\n",
    "\n",
    "\n",
    "class GraphNetwork(nn.Module):\n",
    "  \"\"\"A flax GraphNetwork.\"\"\"\n",
    "  mlp_features: Sequence[int]\n",
    "  edge_pred_features: Sequence[int]\n",
    "  latent_size: int\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, graph):\n",
    "    # Add a global parameter.\n",
    "    graph = graph._replace(globals=jnp.zeros([graph.n_node.shape[0], 1])) \n",
    "\n",
    "    embedder = jraph.GraphMapFeatures(\n",
    "        embed_node_fn=make_embed_fn(self.latent_size),\n",
    "        embed_edge_fn=make_embed_fn(self.latent_size))\n",
    "\n",
    "    net = jraph.GraphNetwork(\n",
    "        update_node_fn=make_mlp(self.mlp_features),\n",
    "        update_edge_fn=make_mlp(self.mlp_features),\n",
    "        )\n",
    "      \n",
    "    updated_graph = net(embedder(graph))\n",
    "    edge_predictions = EdgePredictor(self.edge_pred_features)(updated_graph.edges)\n",
    "    return edge_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((805404, 1), (805404, 1))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = GraphNetwork(mlp_features=(128, 128), latent_size=128, edge_pred_features=(64, 1))\n",
    "# Initialize the network.\n",
    "params = net.init(jax.random.PRNGKey(42), test_graph)\n",
    "output = net.apply(params, test_graph)\n",
    "output.shape, test_graph.edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(3.1936445, dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def l1_loss(logits: np.ndarray, y: np.ndarray, reduction: str = \"mean\") -> np.ndarray:\n",
    "    \"\"\"Implementation of l1_loss.\n",
    "\n",
    "    Args:\n",
    "        logits: model output logits.\n",
    "        y: class labels.\n",
    "        reduction: if reduction is mean, the average is returned, else if it is sum, the sum is returned.\n",
    "\n",
    "    Returns:\n",
    "       l1 loss.\n",
    "    \"\"\"\n",
    "    if reduction == \"mean\":\n",
    "        loss = jnp.mean(jnp.abs(logits - y))\n",
    "    if reduction == \"sum\":\n",
    "        loss = jnp.sum(jnp.abs(logits - y))\n",
    "\n",
    "    return loss\n",
    "\n",
    "l1_loss(output, test_graph.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- number of model parameters:  142977\n"
     ]
    }
   ],
   "source": [
    "from flax.training import train_state\n",
    "from typing import Tuple\n",
    "import optax\n",
    "\n",
    "def create_train_state(\n",
    "    model, graph, tx, rngs\n",
    "):\n",
    "    \"\"\"Train state. This function initializes the model.\"\"\"\n",
    "\n",
    "    @jax.jit\n",
    "    def initialize(params_rng):\n",
    "        variables = model.init(\n",
    "            params_rng,\n",
    "            graph,\n",
    "            # train=False,\n",
    "        )\n",
    "        return variables\n",
    "\n",
    "    variables = initialize(rngs)\n",
    "    state = train_state.TrainState.create(apply_fn=model.apply, params=variables[\"params\"], tx=tx)\n",
    "\n",
    "    param_count = sum(x.size for x in jax.tree_util.tree_leaves(state.params))\n",
    "    print(\"--- number of model parameters: \", param_count)\n",
    "    return state\n",
    "\n",
    "optimizer = optax.adam(learning_rate=1e-4)\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "rngs = {\"params\": rng, \"dropout\": init_rng}\n",
    "\n",
    "model = GraphNetwork(mlp_features=(128, 128), latent_size=128, edge_pred_features=(64, 1))\n",
    "state = create_train_state(\n",
    "    model=model,\n",
    "    graph=test_graph,\n",
    "    tx=optimizer,\n",
    "    rngs=rngs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(\n",
    "    state: train_state.TrainState,\n",
    "    graph: jnp.array,\n",
    "    labels: jnp.ndarray,\n",
    "    rngs: dict,\n",
    ") -> Tuple[train_state.TrainState, tuple]:\n",
    "    \"\"\"Performs one update step over the graph.\n",
    "\n",
    "    Args:\n",
    "        state: training state.\n",
    "        graph: graph node features.\n",
    "        labels: graph classification labels.\n",
    "        rngs: rngs for droupout\n",
    "\n",
    "    Returns:\n",
    "        Current training state, the loss, and logits.\n",
    "    \"\"\"\n",
    "    step = state.step\n",
    "    rngs = {name: jax.random.fold_in(rng, step) for name, rng in rngs.items()}\n",
    "\n",
    "    def loss_fn(params, graph, labels):\n",
    "        # Compute logits and resulting loss.\n",
    "        variables = {\"params\": params}\n",
    "        logits = state.apply_fn(\n",
    "            variables,\n",
    "            graph=graph,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "        loss = l1_loss(logits, labels)\n",
    "        return loss, logits\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(state.params, graph, labels)\n",
    "    new_state = state.apply_gradients(grads=grads)\n",
    "    return new_state, (loss, logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def evaluate_step(\n",
    "    state: train_state.TrainState,\n",
    "    graph: jnp.array,\n",
    "    labels: jnp.ndarray,\n",
    "    dropout_rng: dict = None,\n",
    ") -> tuple:\n",
    "    \"\"\"Performs evaluation step over a set of inputs.\"\"\"\n",
    "    # Get predicted logits, and corresponding probabilities.\n",
    "    variables = {\"params\": state.params}\n",
    "    logits = state.apply_fn(\n",
    "        variables,\n",
    "        graph=graph,\n",
    "        rngs=dropout_rng,\n",
    "    )\n",
    "    loss = l1_loss(logits, labels)\n",
    "    return (loss, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 3.847727060317993, val_loss: 3.684267997741699\n",
      "Epoch: 1, train_loss: 3.6857426166534424, val_loss: 3.5305914878845215\n",
      "Epoch: 2, train_loss: 3.5319674015045166, val_loss: 3.385692834854126\n",
      "Epoch: 3, train_loss: 3.3869986534118652, val_loss: 3.2482481002807617\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_eval(state, train_graph, test_graph, rng):\n",
    "    # Train for 10 epochs\n",
    "    for epoch in range(4):\n",
    "        # Train for one epoch.\n",
    "        rng, epoch_rng = jax.random.split(rng)\n",
    "        epoch_rng = {\"dropout\": epoch_rng}\n",
    "\n",
    "        state, (train_loss, train_logits) = train_step(state=state, graph=train_graph, labels=train_graph.edges, rngs = epoch_rng)\n",
    "\n",
    "        test_loss, test_logits = evaluate_step(state=state, graph=test_graph, labels=test_graph.edges)\n",
    "        print(f\"Epoch: {epoch}, train_loss: {train_loss}, val_loss: {test_loss}\")\n",
    "\n",
    "    return state\n",
    "\n",
    "final_state = train_eval(state, train_graph, test_graph, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indaba_prac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
